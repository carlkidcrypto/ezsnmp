name: Integration Tests
permissions:
  pull-requests: write
  contents: read
concurrency: integration_tests
on:
  push:
    branches: [ main ]

  pull_request:
    branches: [ main ]

jobs:
  check-source-changes:
    runs-on: ubuntu-latest
    outputs:
      run_job: ${{ steps.changed-files.outputs.any_changed }}
    steps:
      - name: Checkout Sourcecode
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v5

      - name: Check for changes in source code
        id: changed-files
        uses: tj-actions/changed-files@e0021407031f5be11a464abee9a0776171c79891 # v47.0.1
        with:
          files: |
            .github/workflows/integration_tests.yml
            ezsnmp/**/*.cpp
            ezsnmp/**/*.h
            integration_tests/**
            python_tests/*.conf
            python_tests/*.py
            setup.cfg
            setup.py

  build-and-integration-test:
    runs-on: ${{ matrix.os }}
    needs: check-source-changes
    timeout-minutes: 15
    if: needs.check-source-changes.outputs.run_job == 'true'
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest]
        python-version: ["3.10", "3.11", "3.12", "3.13", "3.14"]
  
    steps:
      - name: Set up Homebrew
        id: set-up-homebrew
        uses: Homebrew/actions/setup-homebrew@e58f0b60d43355cab9d13c7ecf58a4fbfced93c2 # master

      - name: Set up dependencies
        uses: carlkidcrypto/os-specific-runner@39336e3ec1a53bcdce44b9e9388da204f79203d9 # v2.1.3
        with:
          linux: sudo apt-get update;
                 sudo apt-get install -y snmpd snmp-mibs-downloader;
                 brew update;
                 brew install net-snmp;
                 brew install openssl@3;
                 sudo systemctl stop snmpd;
                 sudo download-mibs;
                 mkdir -p -m 0755 ~/.snmp;
                 echo 'mibs +ALL' > ~/.snmp/snmp.conf;
          
          macos: brew update;
                 brew install net-snmp;
                 brew install openssl@3;
                 echo 'export PATH="/usr/local/opt/net-snmp/bin:$PATH"' >> ~/.zshrc;
                 export PATH="/usr/local/opt/net-snmp/bin:$PATH";
                 echo 'export PATH="/usr/local/opt/net-snmp/sbin:$PATH"' >> ~/.zshrc;
                 export PATH="/usr/local/opt/net-snmp/sbin:$PATH";
                 mkdir -p -m 0755 ~/.snmp;
                 echo 'mibs +ALL' > ~/.snmp/snmp.conf;

      - name: Checkout repo
        uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v5

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 # v6
        with:
          allow-prereleases: true
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@cdf6c1fa76f9f475f3d7449005a359c84ca0f306 # v5.0.3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install pip dependencies
        run: |
          # Integration tests don't need cibuildwheel, skip requirements.txt
          echo "Integration tests don't require additional pip dependencies"

      - name: Build source
        run: |
          if [ "$RUNNER_OS" == "Linux" ]; then
            export LD_LIBRARY_PATH=/home/linuxbrew/.linuxbrew/Cellar/net-snmp/5.9.4/lib:${LD_LIBRARY_PATH:-}
          fi
          python3 -m pip install . --verbose;
          rm -drf build/ ezsnmp.egg-info/;
      
      - name: Start SNMP daemon
        run: |
          if [ "$RUNNER_OS" == "Linux" ]
          then
            mibdir="-M +/var/lib/snmp/mibs"
            SNMPD=$(which snmpd)
          elif [ "$RUNNER_OS" == "macOS" ]
          then
            mibdir=""
            SNMPD=$(which snmpd)
          else
            mibdir=""
            SNMPD=$(which.exe snmpd)
          fi
          $SNMPD -C -c python_tests/snmpd.conf -r -Le $mibdir -m ALL
      
      - name: Run Integration Tests (single)
        uses: carlkidcrypto/os-specific-runner@39336e3ec1a53bcdce44b9e9388da204f79203d9 # v2.1.3
        with:
          linux: |
            export LD_LIBRARY_PATH=/home/linuxbrew/.linuxbrew/Cellar/net-snmp/5.9.4/lib:${LD_LIBRARY_PATH:-}
            cd /home/runner/work/ezsnmp/ezsnmp/integration_tests;
            ./run_integration_tests.sh 2>&1 | tee integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log;
            # Extract key metrics into per-file logs
            grep "Total execution time:" integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log > total_execution_time_${{matrix.os}}_${{matrix.python-version}}.log || true
            grep "usm_unknown_security_name_counter:" integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log > usm_unknown_security_name_counter_${{matrix.os}}_${{matrix.python-version}}.log || true
            grep "connection_error_counter:" integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log > connection_error_counter_${{matrix.os}}_${{matrix.python-version}}.log || true
            # Try to copy the per-test file descriptor log from the output directory saved by the script
            OUT_DIR=$(grep -m1 "Results saved to:" integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log | sed 's/Results saved to: //') || true
            if [ -n "$OUT_DIR" ] && [ -f "$OUT_DIR/test_file_descriptors.log" ]; then
              cp "$OUT_DIR/test_file_descriptors.log" test_file_descriptors_${{matrix.os}}_${{matrix.python-version}}.log || true
            else
              # Fallback: grep relevant lines
              grep -A2 "Running file descriptor tests" integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log > test_file_descriptors_${{matrix.os}}_${{matrix.python-version}}.log || true
            fi
            echo "artifactPath1=/home/runner/work/ezsnmp/ezsnmp/integration_tests/total_execution_time_${{matrix.os}}_${{matrix.python-version}}.log" >> $GITHUB_ENV;
            echo "artifactPath2=/home/runner/work/ezsnmp/ezsnmp/integration_tests/usm_unknown_security_name_counter_${{matrix.os}}_${{matrix.python-version}}.log" >> $GITHUB_ENV;
            echo "artifactPath3=/home/runner/work/ezsnmp/ezsnmp/integration_tests/connection_error_counter_${{matrix.os}}_${{matrix.python-version}}.log" >> $GITHUB_ENV;
            echo "artifactPath4=/home/runner/work/ezsnmp/ezsnmp/integration_tests/test_file_descriptors_${{matrix.os}}_${{matrix.python-version}}.log" >> $GITHUB_ENV;
            echo "artifactPath5=/home/runner/work/ezsnmp/ezsnmp/integration_tests/integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log" >> $GITHUB_ENV;

          macos: |
            cd /Users/runner/work/ezsnmp/ezsnmp/integration_tests;
            ./run_integration_tests.sh 2>&1 | tee integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log;
            # Extract key metrics into per-file logs
            grep "Total execution time:" integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log > total_execution_time_${{matrix.os}}_${{matrix.python-version}}.log || true
            grep "usm_unknown_security_name_counter:" integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log > usm_unknown_security_name_counter_${{matrix.os}}_${{matrix.python-version}}.log || true
            grep "connection_error_counter:" integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log > connection_error_counter_${{matrix.os}}_${{matrix.python-version}}.log || true
            # Try to copy the per-test file descriptor log from the output directory saved by the script
            OUT_DIR=$(grep -m1 "Results saved to:" integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log | sed 's/Results saved to: //') || true
            if [ -n "$OUT_DIR" ] && [ -f "$OUT_DIR/test_file_descriptors.log" ]; then
              cp "$OUT_DIR/test_file_descriptors.log" test_file_descriptors_${{matrix.os}}_${{matrix.python-version}}.log || true
            else
              # Fallback: grep relevant lines
              grep -A2 "Running file descriptor tests" integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log > test_file_descriptors_${{matrix.os}}_${{matrix.python-version}}.log || true
            fi
            echo "artifactPath1=/Users/runner/work/ezsnmp/ezsnmp/integration_tests/total_execution_time_${{matrix.os}}_${{matrix.python-version}}.log" >> $GITHUB_ENV;
            echo "artifactPath2=/Users/runner/work/ezsnmp/ezsnmp/integration_tests/usm_unknown_security_name_counter_${{matrix.os}}_${{matrix.python-version}}.log" >> $GITHUB_ENV;
            echo "artifactPath3=/Users/runner/work/ezsnmp/ezsnmp/integration_tests/connection_error_counter_${{matrix.os}}_${{matrix.python-version}}.log" >> $GITHUB_ENV;
            echo "artifactPath4=/Users/runner/work/ezsnmp/ezsnmp/integration_tests/test_file_descriptors_${{matrix.os}}_${{matrix.python-version}}.log" >> $GITHUB_ENV;
            echo "artifactPath5=/Users/runner/work/ezsnmp/ezsnmp/integration_tests/integration_tests_full_${{matrix.os}}_${{matrix.python-version}}.log" >> $GITHUB_ENV;
      
      - name: Upload Integration Test Results
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v5
        with:
          name: integration-test-results_${{matrix.os}}_${{matrix.python-version}}
          path: |
            ${{ env.artifactPath1 }}
            ${{ env.artifactPath2 }}
            ${{ env.artifactPath3 }}
            ${{ env.artifactPath4 }}
            ${{ env.artifactPath5 }}

  pr-summary:
    needs: build-and-integration-test
    if: github.event_name == 'pull_request'
    runs-on: ubuntu-latest
    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v7
        with:
          path: artifacts

      - name: Prepare PR integration-test summary
        run: |
          python3 -c "
          import os
          import re
          import statistics
          
          data = {}
          for root, dirs, files in os.walk('artifacts'):
              for file in files:
                  if file.startswith('integration_tests_full_') and file.endswith('.log'):
                      log_path = os.path.join(root, file)
                      with open(log_path, 'r') as f:
                          lines = f.readlines()
                      for line in lines:
                          match = re.search(r'(\w+): - (\d+) - (.+): (.+)', line.strip())
                          if match:
                              test_type, num, field, value = match.groups()
                              num = int(num)
                              try:
                                  val = float(value.split()[0])
                              except ValueError:
                                  continue
                              key = (test_type, num, field)
                              if key not in data:
                                  data[key] = []
                              data[key].append(val)
          
          # Start building the summary with a table
          summary = '<!-- integration-test-summary -->\\n## Integration Test Results \\u23f1\\ufe0f\\n\\n'
          summary += '| Test Type | Workers | Field | Min (s) | Max (s) | Avg (s) | StdDev \\U0001f4ca |\\n'
          summary += '|-----------|---------|-------|---------|---------|---------|----------|\\n'

          for key in sorted(data.keys()):
              test_type, num, field = key
              values = data[key]

              # Format test type to be more readable
              test_name = test_type.replace('_', ' ').title()

              if len(values) > 1:
                  min_v = min(values)
                  max_v = max(values)
                  avg_v = statistics.mean(values)
                  std_v = statistics.stdev(values)
                  summary += f'| {test_name} | {num} | {field} | {min_v:.3f} | {max_v:.3f} | {avg_v:.3f} | {std_v:.3f} |\\n'
              elif len(values) == 1:
                  summary += f'| {test_name} | {num} | {field} | {values[0]:.3f} | {values[0]:.3f} | {values[0]:.3f} | N/A |\\n'

          # Add file descriptor test results
          summary += '\n### File Descriptor Tests \U0001f4c1\n\n'
          fd_records = []
          for root, dirs, files in os.walk('artifacts'):
            for file in files:
              if file.startswith('test_file_descriptors_') and file.endswith('.log'):
                log_path = os.path.join(root, file)
                with open(log_path, 'r') as f:
                  content = f.read()

                # State-based parser: track current (session, operation, mode) block
                current_record = None
                for line in content.split('\n'):
                  # Detect block start: 'Running work_op_no_close: get SESS_V1_ARGS'
                  running_match = re.search(
                    r'Running (work_(?:get|op)_no_close|work_(?:get|op)_close):\s*(\S+)(?:\s+(\S+))?',
                    line,
                  )
                  if running_match:
                    if current_record and 'session' in current_record:
                      fd_records.append(current_record)
                    mode_raw, op_or_sess, sess_opt = running_match.groups()
                    if sess_opt:
                      operation = op_or_sess
                      sess = sess_opt
                    else:
                      operation = 'unknown'
                      sess = op_or_sess
                    current_record = {
                      'session': sess,
                      'operation': operation,
                      'mode': 'no close' if 'no_close' in mode_raw else 'close'
                    }
                    continue

                  if current_record is None:
                    continue

                  m = re.search(r'Subprocess PID:? Open FDs before:\s*(\d+)', line)
                  if m:
                    current_record['fd_before'] = int(m.group(1))

                  m = re.search(r'Subprocess PID\s*Open FDs after:\s*(\d+)', line)
                  if m:
                    current_record['fd_after'] = int(m.group(1))

                  m = re.search(r'Total execution time:\s*([\d.]+)', line)
                  if m:
                    current_record['exec_time'] = float(m.group(1))

                  m = re.search(r'Average time per SNMP call.*?:\s*([\d.]+)', line)
                  if m:
                    current_record['avg_time'] = float(m.group(1))

                if current_record and 'session' in current_record:
                  fd_records.append(current_record)

            if fd_records:
              # Group by (session, operation, mode) and aggregate across matrix combos
              grouped = {}
              for rec in fd_records:
                key = (rec['session'], rec.get('operation', 'unknown'), rec['mode'])
                if key not in grouped:
                  grouped[key] = {'fd_before': [], 'fd_after': [], 'exec_time': [], 'avg_time': []}
                for field in ['fd_before', 'fd_after', 'exec_time', 'avg_time']:
                  if field in rec:
                    grouped[key][field].append(rec[field])

              summary += '| Session Type | Operation | Mode | FD Before | FD After | FD Leak | Exec Time (s) | Avg/Call (s) |\\n'
              summary += '|--------------|-----------|------|-----------|----------|---------|---------------|--------------|\\n'

              for (sess, operation, mode) in sorted(grouped.keys()):
                g = grouped[(sess, operation, mode)]
                sess_display = sess.replace('SESS_', '').replace('_ARGS', '')
                op_display = operation
                fb_vals = g['fd_before']
                fa_vals = g['fd_after']
                exec_vals = g['exec_time']
                avg_vals = g['avg_time']
                if fb_vals and fa_vals:
                  fb = statistics.mean(fb_vals)
                  fa = statistics.mean(fa_vals)
                  leak = fa - fb
                  fb_str = f'{fb:.0f}'
                  fa_str = f'{fa:.0f}'
                  leak_str = f'{leak:+.0f}'
                else:
                  fb_str = fa_str = leak_str = '-'
                et = f'{statistics.mean(exec_vals):.3f}' if exec_vals else '-'
                at = f'{statistics.mean(avg_vals):.6f}' if avg_vals else '-'
                summary += f'| {sess_display} | {op_display} | {mode} | {fb_str} | {fa_str} | {leak_str} | {et} | {at} |\\n'

              summary += '\\n\\u2705 File descriptor tests completed successfully\\n'
            else:
              summary += '\\u274c No file descriptor test results found\\n'

          with open('integration_test_summary.md', 'w') as f:
              f.write(summary)
          "
          echo "Summary prepared: integration_test_summary.md"

      - name: Find existing integration-test summary comment
        id: find-integration-comment
        uses: peter-evans/find-comment@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          issue-number: ${{ github.event.pull_request.number }}
          comment-author: 'github-actions[bot]'
          body-includes: '<!-- integration-test-summary -->'

      - name: Update PR comment with integration-test summary
        uses: peter-evans/create-or-update-comment@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          issue-number: ${{ github.event.pull_request.number }}
          comment-id: ${{ steps.find-integration-comment.outputs.comment-id }}
          body-file: integration_test_summary.md
          edit-mode: replace
          comment-tag: integration-test-summary